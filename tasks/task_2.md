
# Контекстно-независимое векторное представление слов 

## Вариант 1

1. Используйте тексты из предыдущего задания и обучите на них модель векторного представления слов (опционально можно приводить слова к нормальной форме и удалить стоп-слова). Можно использовать `gensim`.

2. Разделите коллекцию текстов на обучающее и тестовое множество. С помощью обученной модели векторного представления отобразите каждый документ в вектор, усреднив все вектора для слов документа. 

3. Используйте какой-либо алгоритм классификации (например `SVM`) для классификации текстов. Для обучения используйте тестовое множество, для анализа результатов - тестовое.

4. Простое усреднение векторов слов обычно не дает хорошего отображения документа в вектор. Придумайте альтернативный способ. Протестируйте его, повторно обучив алгоритм классификации на тех же данных. 

## Вариант 2

Нужно создать некоторый аналог утилиты [Grep](https://ru.wikipedia.org/wiki/Grep) для поиска строк в текстовом файле, который бы учитывал похожие по смыслу слова.
Grep применяется для поиска строк в текстовым файле, которые соответствуют/содержат какой-то паттерн.  Упрощенно - содержат какое-то слово.

Например команда
	> grep “привет” data.txt
 или
    > cat data.txt | grep “привет”     
выведет все строки файла data.txt, которые содержат “привет”.

Требуется реализовать утилиту на языке Python,  но в отличие от стандартного grep, утилита должна поддерживать поиск не только по точным совпадениям, но и с учетом  синонимов, для чего можно использовать модель Word2Vec или аналогичные неконтекстные векторные представления слов.

Например команда:
> python3 mygrep.py data.txt “привет”

В идеальном варианте должна вывести все строки в файле data.txt, которые содержат слова “привет”, “здравствуйте” и т.п.

Для обучения и применения Word2Vec можно использовать библиотеку gensim и набор текстов из предыдущего задания. Подумайте, как обрабатывать случаи, когда синонимы слова не найдены или если модель Word2Vec не содержит (OOV- out of vocabulary) введенное слово. В коде нужно предусмотреть дополнительную обработку ошибок, связанных с чтением файла, загрузкой модели и т.п.